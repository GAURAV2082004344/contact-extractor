ðŸš€ About Contact Extractor
It is a Python scraper that extracts name, emails, and phone numbers from directory cards on the first results page, using Playwright to interact with filters when the page initially shows no results.

ðŸ’¡ How it works

Loads each target directory URL, dismisses cookie banners, selects non-empty options for sector/country, optionally clicks a Search/Apply button, and scrolls to trigger lazy loading.

Once cards are visible, it parses inline tiles under the grid and extracts h5 titles, mailto/tel anchors, and additional contacts via regex from the card text.

âœ¨ Features

First-page card scraping with grid-scoped selectors to avoid footer/global noise.

Optional Playwright-based filter interaction for empty-state pages that require a search trigger.

Email and phone extraction with regex, plus de-duplication of candidates.

Simple CLI usage with URLs provided in a urls.txt file.â€‹

âš™ï¸ Installation

Create and activate a virtual environment:

python -m venv .venvâ€‹

.venv\Scripts\Activate.ps1â€‹

Install dependencies and browser:

pip install -r requirements.txtâ€‹

python -m playwright install chromiumâ€‹

ðŸ“ Project layout

contact_spider/spiders/contacts.py â€” the spider (if inside a Scrapy project) OR contact_spider/contact_spider/spiders/contacts.py if using runspider.â€‹

urls.txt â€” one URL per line for target directories.â€‹

results/ â€” outputs such as run.json.â€‹

README.md, NOTES.md â€” docs and limitations.â€‹

â™¨ï¸ Usage
A. Run without a Scrapy project (single-file mode)

From the repo root:

.venv\Scripts\python -m scrapy runspider contact_spider\contact_spider\spiders\contacts.py -a url_file=urls.txt -s ROBOTSTXT_OBEY=False -s CONCURRENT_REQUESTS=2 -s PLAYWRIGHT_MAX_CONTEXTS=1 -s PLAYWRIGHT_MAX_PAGES_PER_CONTEXT=1 -O results\run.jsonâ€‹

B. Run inside a Scrapy project (optional)

Initialize once:

.venv\Scripts\python -m scrapy startproject contact_spider .â€‹

Move spider to contact_spider\spiders\contacts.py, then:

Crawl:

.venv\Scripts\python -m scrapy crawl contacts -a url_file=urls.txt -s ROBOTSTXT_OBEY=False -s CONCURRENT_REQUESTS=2 -s PLAYWRIGHT_MAX_CONTEXTS=1 -s PLAYWRIGHT_MAX_PAGES_PER_CONTEXT=1 -O results\run.jsonâ€‹

ðŸ”Ž Verifying selectors (Scrapy shell)

Launch:

scrapy shell "YOUR_RESULTS_URL"â€‹

At >>>:

len(response.css("body > main > section > div.py-12 > div > div.mt-5 > div")) # should be > 1 when cards exist

response.css("body > main > section > div.py-12 > div > div.mt-5 ::text").re_first(r"We were not able to find the results") # should be None when populated

ðŸ§ª Example command

.venv\Scripts\python -m scrapy runspider contact_spider\contact_spider\spiders\contacts.py -a url_file=urls.txt -O results\run.jsonâ€‹

ðŸ“¦ Sample output format (JSON line)

{"url":"https://example.com/directory","profile_in_page":true,"name_candidates":["Jane Doe"],"emails":["jane@example.com"],"phones":["+1 555 123 4567"],"socials":[],"notes":{}}


